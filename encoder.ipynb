{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<div style=\"text-align: center\">ENCODER</div>**\n",
    "=======================================================================================================================================\n",
    "\n",
    "    + this is a sub-system that helps create embeddings of audio samples\n",
    "    + this is trained on audio samples and is trained to minimize the similarty of embeddings of utterences that from the same speaker and maximize that between different speakers\n",
    "======================================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path(\"C:/Users/Swaroop/Downloads/train-clean-100/LibriSpeech/train-clean-100/train-clean-100/\")\n",
    "outdir = Path(\"./encoder/outdir\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SECTION 1:** Dataset preparation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stpes of data preparation - \n",
    "1. load the audio files using `librosa` \n",
    "2. preprocess the wav and save it as a numpy file in the resptive speaker dir in the outdir.\n",
    "3. store the meta data of every utterence in the speaker dir in a `sources.txt` with the same folder.\n",
    "    \n",
    "    `one such entry` :\n",
    "         \n",
    "        \"495_26-495-0002.npy ,  C:\\Users\\Swaroop\\Downloads\\train-clean-100\\LibriSpeech\\train-clean-100\\26\\495\\26-495-0002.flac\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder import params_data, params_model\n",
    "from encoder.audio import *\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union\n",
    "from warnings import warn\n",
    "import warnings\n",
    "import numpy as np\n",
    "import librosa\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: we are implementing the preprocessing tailored for libritts dataset as it the only datset we have  used in this project.\n",
    "\n",
    "other functions pertaining to the preprocessing of other datasets have been omited."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing functions call heirarchy -  `preprocess_datset()` --**calls**--> `preprocess_speaker()` --**calls**--> `preprocess_utterences()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder.audio import * \n",
    "from encoder.params_data import * \n",
    "\n",
    "_AUDIO_EXTENSIONS = (\"wav\", \"flac\", \"m4a\", \"mp3\")\n",
    "\n",
    "def _preprocess_speaker(speaker_dir: Path, datasets_root: Path, out_dir: Path, skip_existing: bool = True):\n",
    "    # Give a name to the speaker that includes its dataset\n",
    "    speaker_name = \"_\".join(speaker_dir.relative_to(datasets_root).parts)\n",
    "\n",
    "    # Create an output directory with that name, as well as a txt file containing a\n",
    "    # reference to each source file.\n",
    "    speaker_out_dir = out_dir.joinpath(speaker_name)\n",
    "    speaker_out_dir.mkdir(exist_ok=True)\n",
    "    sources_fpath = speaker_out_dir.joinpath(\"_sources.txt\")\n",
    "\n",
    "    # There's a possibility that the preprocessing was interrupted earlier, check if\n",
    "    # there already is a sources file.\n",
    "    if sources_fpath.exists():\n",
    "        try:\n",
    "            with sources_fpath.open(\"r\") as sources_file:\n",
    "                existing_fnames = {line.split(\",\")[0] for line in sources_file}\n",
    "        except:\n",
    "            existing_fnames = {}\n",
    "    else:\n",
    "        existing_fnames = {}\n",
    "\n",
    "    # Gather all audio files for that speaker recursively\n",
    "    sources_file = sources_fpath.open(\"a\" if skip_existing else \"w\")\n",
    "    audio_durs = []\n",
    "    for extension in _AUDIO_EXTENSIONS:\n",
    "        for in_fpath in speaker_dir.glob(\"**/*.%s\" % extension):\n",
    "            # Check if the target output file already exists\n",
    "            out_fname = \"_\".join(in_fpath.relative_to(speaker_dir).parts)\n",
    "            out_fname = out_fname.replace(\".%s\" % extension, \".npy\")\n",
    "            if skip_existing and out_fname in existing_fnames:\n",
    "                continue\n",
    "\n",
    "            # Load and preprocess the waveform\n",
    "            wav = preprocess_wav(in_fpath)\n",
    "            if len(wav) == 0:\n",
    "                continue\n",
    "\n",
    "            frames = wav_to_mel_spectrogram(wav)\n",
    "            if len(frames) < partials_n_frames:\n",
    "                continue\n",
    "\n",
    "            out_fpath = speaker_out_dir.joinpath(out_fname)\n",
    "            np.save(out_fpath, frames)\n",
    "            sources_file.write(\"%s,%s\\n\" % (out_fname, in_fpath))\n",
    "            audio_durs.append(len(wav) / sampling_rate)\n",
    "\n",
    "    sources_file.close()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path(\"C:/Users/Swaroop/Downloads/train-clean-100/LibriSpeech/train-clean-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_dir = Path(\".\").joinpath(\"test-Out_directory2\")\n",
    "test_out_dir.mkdir(exist_ok= True)\n",
    "_preprocess_speaker(dataset_root.joinpath(\"19\"), datasets_root= dataset_root, out_dir=test_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preprocessing_to_all_speakers(data_set_root: Path):\n",
    "    speakers = list(data_set_root.glob(\"*\"))\n",
    "    for speaker in speakers:\n",
    "        _preprocess_speaker(speaker, datasets_root= dataset_root, out_dir=outdir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply the preprocessing to all the speakers. (this could take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_preprocessing_to_all_speakers(dataset_root)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the above function to apply preprocessing to all the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SECTION 2:** Model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the imput to train the model is the same as theoutdir that we generated during preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "running the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from encoder.model2 import SpeakerEncoder\n",
    "from encoder.train import train\n",
    "import torch \n",
    "clean_dataset_root = Path(\"./outdir2/\")\n",
    "model = SpeakerEncoder(torch.device('cpu'), torch.device('cpu'))\n",
    "new_models_dir = Path('./new_model_dir/')\n",
    "new_models_dir.mkdir(exist_ok=True)\n",
    "train(\"1\", clean_dataset_root, new_models_dir, 10, 10, 10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SECTION 3:** Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder inference module implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_embed(encoder_model_path, audio_file_path):\n",
    "    \n",
    "    # imports    \n",
    "    from encoder import inference2 as encoder\n",
    "    from encoder.audio import preprocess_wav\n",
    "    import librosa\n",
    "    \n",
    "    # model loading    \n",
    "    encoder.load_model(encoder_model_path)    \n",
    "    original_wav, sampling_rate = librosa.load(audio_file_path)\n",
    "    preprocessed_wav = preprocess_wav(original_wav, sampling_rate)\n",
    "    \n",
    "    # generating embeds    \n",
    "    embed = encoder.embed_utterance(preprocessed_wav, using_partials = False)\n",
    "    \n",
    "    return embed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SECTION 4:** COMPARING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model = Path(\"./new_model_dir/1/encoder.pt\")\n",
    "saved_model = Path(\"C:/Users/Swaroop/OneDrive/Documents/Real-Time-Voice-Cloning-master/saved_models/default/encoder.pt\")\n",
    "audio_fpath = Path(\"C:/Users/Swaroop/Downloads/both.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoder \"encoder.pt\" trained to step 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Swaroop\\real-time-voice-cloner\\encoder\\audio.py:42: FutureWarning: Pass orig_sr=22050, target_sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  wav = librosa.resample(wav, source_sr, sampling_rate)\n",
      "c:\\Users\\Swaroop\\real-time-voice-cloner\\encoder\\audio.py:58: FutureWarning: Pass y=[-0.02705792 -0.04254879 -0.03892137 ... -0.03959629 -0.04196231\n",
      " -0.04154412], sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  frames = librosa.feature.melspectrogram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00660599 0.13609818 0.08857831 0.0828993  0.02956464 0.03854567\n",
      " 0.         0.19567405 0.02477263 0.01610441 0.06377555 0.\n",
      " 0.         0.         0.05463692 0.15310887 0.01248206 0.15648209\n",
      " 0.         0.         0.05015788 0.01215473 0.         0.\n",
      " 0.09444315 0.         0.         0.10352036 0.0528067  0.12740873\n",
      " 0.06806444 0.         0.09161198 0.         0.06622141 0.\n",
      " 0.         0.         0.         0.02857352 0.         0.\n",
      " 0.05949973 0.         0.01280187 0.         0.05263649 0.\n",
      " 0.         0.06459756 0.03689168 0.         0.         0.10369769\n",
      " 0.06628977 0.         0.         0.15247673 0.         0.\n",
      " 0.02736049 0.         0.1837995  0.         0.01261522 0.08031336\n",
      " 0.04983153 0.         0.         0.06262928 0.         0.\n",
      " 0.06637316 0.14579009 0.0546518  0.05780488 0.         0.03637395\n",
      " 0.04982163 0.02094671 0.         0.04942364 0.         0.\n",
      " 0.         0.         0.         0.09269736 0.06819349 0.\n",
      " 0.14063959 0.         0.         0.00898665 0.         0.12328354\n",
      " 0.04404202 0.         0.         0.         0.         0.\n",
      " 0.05170007 0.02717485 0.08131041 0.03694046 0.         0.08133116\n",
      " 0.09612851 0.1218521  0.         0.         0.         0.\n",
      " 0.01700932 0.12304261 0.         0.10440038 0.1378685  0.02153959\n",
      " 0.         0.         0.         0.04035249 0.10638334 0.\n",
      " 0.         0.         0.03476269 0.         0.         0.\n",
      " 0.01633795 0.         0.05295613 0.0482792  0.02380651 0.\n",
      " 0.16809666 0.01145262 0.02061275 0.17719127 0.         0.07555311\n",
      " 0.         0.05765412 0.         0.09303258 0.         0.\n",
      " 0.02483684 0.02808464 0.         0.13966627 0.         0.05830767\n",
      " 0.         0.11678971 0.         0.01344257 0.         0.02430564\n",
      " 0.01691424 0.         0.05576443 0.         0.         0.\n",
      " 0.         0.05562717 0.00170125 0.         0.05239755 0.11107571\n",
      " 0.         0.01738133 0.         0.01725239 0.11763132 0.\n",
      " 0.06548425 0.         0.         0.         0.04849157 0.\n",
      " 0.         0.01820276 0.         0.         0.17645046 0.\n",
      " 0.10806765 0.11065787 0.         0.         0.01582206 0.\n",
      " 0.         0.         0.00667424 0.13967076 0.         0.1398173\n",
      " 0.         0.16068178 0.07617196 0.         0.01764668 0.\n",
      " 0.         0.1644345  0.         0.01471937 0.00743295 0.07219069\n",
      " 0.0557051  0.         0.01748146 0.         0.         0.\n",
      " 0.05436335 0.         0.         0.07846144 0.         0.\n",
      " 0.08651479 0.         0.14747225 0.00181336 0.06289127 0.\n",
      " 0.06756721 0.         0.         0.09745523 0.06877779 0.\n",
      " 0.13202834 0.         0.         0.         0.00135135 0.\n",
      " 0.         0.13046874 0.01958939 0.12780114 0.18473107 0.07518536\n",
      " 0.1864257  0.         0.06861555 0.0463566 ]\n"
     ]
    }
   ],
   "source": [
    "embed = load_and_embed(our_model, audio_fpath)\n",
    "print(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoder \"encoder.pt\" trained to step 1564501\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.09819598e-01 0.00000000e+00 0.00000000e+00 1.43052042e-02\n",
      " 0.00000000e+00 0.00000000e+00 9.58929583e-02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.67490016e-02\n",
      " 1.62922353e-01 0.00000000e+00 5.86892851e-02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.07819758e-01 0.00000000e+00 9.01186392e-02\n",
      " 0.00000000e+00 0.00000000e+00 2.71619111e-01 2.09977657e-01\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.63994402e-01\n",
      " 0.00000000e+00 0.00000000e+00 1.01646684e-01 4.18301821e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.28442049e-01 0.00000000e+00 2.21534491e-01 0.00000000e+00\n",
      " 1.72901466e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.27915072e-02\n",
      " 6.05602637e-02 0.00000000e+00 1.51717395e-01 1.88433260e-01\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.48492903e-01\n",
      " 0.00000000e+00 1.67062610e-01 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 6.36988729e-02\n",
      " 0.00000000e+00 0.00000000e+00 1.07683726e-01 5.32214418e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.12129425e-02\n",
      " 0.00000000e+00 0.00000000e+00 1.86715618e-01 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 9.15062337e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.56674966e-01 8.72739181e-02\n",
      " 2.11373046e-02 8.30199197e-02 1.06103733e-01 1.21739149e-01\n",
      " 0.00000000e+00 7.15956017e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.06593154e-01 4.14723121e-02 0.00000000e+00\n",
      " 0.00000000e+00 7.93631747e-02 7.37383729e-03 1.50220275e-01\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.84827279e-02 1.30992029e-02 6.20541088e-02 5.24776205e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.49477308e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 7.06953108e-02 0.00000000e+00 0.00000000e+00 1.43301142e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.48160383e-01 0.00000000e+00 1.16359621e-01 0.00000000e+00\n",
      " 9.01287571e-02 0.00000000e+00 6.12679077e-03 0.00000000e+00\n",
      " 0.00000000e+00 5.33513762e-02 0.00000000e+00 4.33091484e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.42325267e-01 6.93365037e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.76830098e-01 3.24595859e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 3.11894957e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.08219357e-02 0.00000000e+00 5.19416928e-02\n",
      " 1.62801176e-01 0.00000000e+00 1.08286493e-01 3.11921965e-02\n",
      " 4.61596362e-02 0.00000000e+00 0.00000000e+00 1.58690587e-01\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.07146695e-01\n",
      " 0.00000000e+00 1.43620083e-02 0.00000000e+00 0.00000000e+00\n",
      " 1.00921951e-01 2.40711384e-02 0.00000000e+00 2.06423819e-01\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.52273387e-01\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.23900317e-01\n",
      " 1.47307575e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.33252011e-02 1.02114995e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.86569558e-02 1.29098222e-01 0.00000000e+00\n",
      " 2.94607952e-02 5.96236773e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 5.74438423e-02 0.00000000e+00 4.36403416e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.89220179e-02 0.00000000e+00 0.00000000e+00 9.76143554e-02\n",
      " 0.00000000e+00 1.08166486e-01 9.69014689e-02 1.53323803e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.05306928e-02\n",
      " 0.00000000e+00 6.02353849e-02 0.00000000e+00 0.00000000e+00\n",
      " 1.04729712e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed = load_and_embed(saved_model, audio_fpath)\n",
    "print(embed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
